// Increased the amount of work-per-thread by a factor WPT and use shared memory
__global__ void SparseMatMulKernelX(float* val, int* col_indx, int* row_indx, float* dense, 
								    float* out, int width, int width2, int out_row)
{
	int out_col = width2;

	int global_row = blockIdx.y*blockDim.y+threadIdx.y;
	int global_col = blockIdx.x*blockDim.x*WPT+threadIdx.x;

	if(DEBUG) {
      	printf("Row: %d, Col: %d, blockIdx.x: %d, blockIdx.y: %d, blockDim.x: %d, blockDim.y: %d, WPT: %d      From device\n", 
      			global_row, global_col, blockIdx.x, blockIdx.y, blockDim.x, blockDim.y, WPT);
    }

	if(global_row<out_row && global_col <out_col/WPT) { //!!!
		int row_start = row_indx[global_row];
		int row_end = row_indx[global_row+1];
		int row_amount = row_end - row_start;
		int row_count = 0;

		if(DEBUG) {
      		printf("Row: %d, Col: %d, row_start: %d, row_end: %d, row_amount: %d, row_count: %d, WPT: %d      From device\n", 
      				global_row, global_col, row_start, row_end, row_amount, row_count, WPT);
      	}

		__shared__ float val_sub[BLOCK_SIZE];
		__shared__ int col_indx_sub[BLOCK_SIZE];

        val_sub[threadIdx.x] = 0;
        col_indx_sub[threadIdx.x] = 0;

		// Initialise the accumulation registers	
		float product_val[WPT];
		for (int w=0; w<WPT; w++) {
        	product_val[w] = 0;
    	}

    	__syncthreads();

    	for(row_count = 0; row_count < (row_amount+BLOCK_SIZE); row_count += BLOCK_SIZE) {

    		//Need all threads to reach barrier in conditional code
    		if((threadIdx.x+row_count) >= row_amount) {
    			val_sub[threadIdx.x] = 0;
    			col_indx_sub[threadIdx.x] = 0;
    		}
    		else {
    			val_sub[threadIdx.x] = val[row_start + row_count + threadIdx.x];
    			col_indx_sub[threadIdx.x] = col_indx[row_start + row_count + threadIdx.x];
    		}
    		__syncthreads();

    		/*if(global_row == 2 && global_col == 0 && DEBUG) {
      			for (int w=0; w<BLOCK_SIZE; w++) {
      				printf("%f ", val_sub[w]);
      			}
      			printf("\n");
      		}*/	

      		if(DEBUG) {
      			printf("row: %d, col: %d, vals_subs:%f, %f, %f, %f \n", global_row, global_col, 
      					val_sub[0], val_sub[1], val_sub[2], val_sub[3]);
      		}

      		for(int k = 0; k < min(BLOCK_SIZE, row_amount - row_count); k++) {
      		//for(int k = 0; k < BLOCK_SIZE; k++) {
    			for (int w=0; w<WPT; w++) {
        			float temp = product_val[w];
        			product_val[w] += val_sub[k] * dense[col_indx_sub[k]*width2 + global_col + w];
        			//product_val += val[k] * dense[col_indx[k]*width2 + col];
        			if(DEBUG) {
      					printf("Global_row: %d, Global_col: %d, product_val[w]: %f, previous: temp: %f, k: %d, val_sub[k]: %f, dense[...]: %f, w: %d\n", 
      					global_row, global_col, product_val[w], temp, k, val_sub[k], dense[col_indx_sub[k]*width2 + global_col + w], w);
      				}		
				}
    		}

    		__syncthreads();
    	}

    	for (int w=0; w<WPT; w++) {
        	out[global_row*width2+global_col+w] = product_val[w];
        	//out[global_row*width2+global_col] = product_val;
    	}

	}
}
















// Version of 2 for debugging purposes
// Increased the amount of work-per-thread by a factor WPT and use shared memory
__global__ void SparseMatMulKernel3(float* val, int* col_indx, int* row_indx, float* dense, 
								    float* out, int width, int width2, int out_row)
{
	int out_col = width2;

	int global_row = blockIdx.y*blockDim.y+threadIdx.y;
	int global_col = blockIdx.x*blockDim.x+threadIdx.x;

	if(global_row<out_row && global_col <out_col) {
		int row_start = row_indx[global_row];
		int row_end = row_indx[global_row+1];
		int row_amount = row_end - row_start;
		int row_count = 0;

		__shared__ float val_sub[BLOCK_SIZE];
		__shared__ int col_indx_sub[BLOCK_SIZE];

        val_sub[threadIdx.x] = 0;
        col_indx_sub[threadIdx.x] = 0;

        float product_val;
		product_val = 0;

    	__syncthreads();

    	for(row_count = 0; row_count < (row_amount+BLOCK_SIZE); row_count += BLOCK_SIZE) {

    		//Need all threads to reach barrier in conditional code
    		if((threadIdx.x+row_count) >= row_amount) {
    			val_sub[threadIdx.x] = 0;
    			col_indx_sub[threadIdx.x] = 0;
    		}
    		else {
    			val_sub[threadIdx.x] = val[row_start + row_count + threadIdx.x];
    			col_indx_sub[threadIdx.x] = col_indx[row_start + row_count + threadIdx.x];
    		}
    		__syncthreads();


      		if(DEBUG) {
      			printf("row: %d, col: %d, vals_subs:%f, %f, %f, %f \n", global_row, global_col, 
      					val_sub[0], val_sub[1], val_sub[2], val_sub[3]);
      		}

      		for(int k = 0; k < min(BLOCK_SIZE, row_amount - row_count); k++) {
      		// for(int k = 0; k < BLOCK_SIZE; k++) {
      		    float temp = product_val;
        		product_val += val_sub[k] * dense[col_indx_sub[k]*width2 + global_col];	

        		if(DEBUG) {
      				printf("Global_row: %d, Global_col: %d, product_val: %f, previous: temp: %f, k: %d, val_sub[k]: %f, dense[...]: %f\n", 
      				global_row, global_col, product_val, temp, k, val_sub[k], dense[col_indx_sub[k]*width2 + global_col]);
      			}	
    		}

    		__syncthreads();
    	}

        out[global_row*width2+global_col] = product_val;

	}
}
