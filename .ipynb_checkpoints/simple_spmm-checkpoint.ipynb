{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required modules\n",
    "import pyopencl as cl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS = 4\n",
    "THREADS = 256\n",
    "M = 4\n",
    "N = 3\n",
    "K = 5\n",
    "M = TS\n",
    "N = TS\n",
    "K = TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<4x4 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 5 stored elements in Compressed Sparse Row format>,\n",
       " matrix([[5.6411579e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "         [7.2199875e-01, 9.3855274e-01, 0.0000000e+00, 9.9221158e-01],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.7876583e-04],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "        dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.rand.html\n",
    "\n",
    "from scipy.sparse import random\n",
    "from scipy import stats\n",
    "\n",
    "# double / float 64 support is not really general\n",
    "# https://streamhpc.com/blog/2013-10-17/writing-opencl-code-single-double-precision/\n",
    "sparse = random(M, N, density=0.33, format=\"csr\", random_state=42, dtype = np.float32)\n",
    "sparse_to_dense = sparse.todense()\n",
    "\n",
    "sparse, sparse_to_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.6411579e-02, 7.2199875e-01, 9.3855274e-01, 9.9221158e-01,\n",
       "        7.7876583e-04], dtype=float32),\n",
       " array([0, 0, 1, 3, 3], dtype=int32),\n",
       " array([0, 1, 4, 5, 5], dtype=int32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = sparse.data\n",
    "col = sparse.indices\n",
    "rowptr = sparse.indptr\n",
    "\n",
    "value, col, rowptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72199875"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37454012, 0.9507143 , 0.7319939 , 0.5986585 ],\n",
       "       [0.15601864, 0.15599452, 0.05808361, 0.8661761 ],\n",
       "       [0.601115  , 0.7080726 , 0.02058449, 0.96990985],\n",
       "       [0.83244264, 0.21233912, 0.18182497, 0.1834045 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# dense = np.random.rand(N, K)\n",
    "dense = np.random.rand(N,K).astype(np.float32)\n",
    "dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "#sparse @ dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.      , 0.      , 0.      , 3.943829],\n",
       "        [0.      , 0.      , 7.682296, 0.      ],\n",
       "        [0.      , 5.5397  , 0.      , 0.      ],\n",
       "        [0.      , 1.975514, 0.      , 0.      ],\n",
       "        [0.      , 7.9844  , 0.      , 0.      ]]),\n",
       " array([[4.773971, 6.288709, 3.647845],\n",
       "        [5.134009, 9.522297, 9.161951],\n",
       "        [6.357117, 7.172969, 1.416026],\n",
       "        [6.069689, 0.163006, 2.428868]]),\n",
       " array([[23.9378155 ,  0.64286779,  9.57904006],\n",
       "        [48.8372545 , 55.10487106, 10.87833088],\n",
       "        [28.44086966, 52.75066869, 50.75445995],\n",
       "        [10.14230666, 18.81143104, 18.09956247],\n",
       "        [40.99198146, 76.02982817, 73.15268156]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sparse2 = np.array([[0.000000,     0.000000,     0.000000,     3.943829],\n",
    "                    [0.000000,     0.000000,     7.682296,     0.000000],\n",
    "                    [0.000000,     5.539700,     0.000000,     0.000000],\n",
    "                    [0.000000,     1.975514,     0.000000,     0.000000],\n",
    "                    [0.000000,     7.984400,     0.000000,     0.000000]])\n",
    "dense2 = np.array([[4.773971,     6.288709,     3.647845],\n",
    "                   [5.134009,     9.522297,     9.161951],\n",
    "                   [6.357117,     7.172969,     1.416026],\n",
    "                   [6.069689,     0.163006,     2.428868]])\n",
    "out2 = sparse2@dense2\n",
    "sparse2, dense2, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1128399e-02, 5.3631295e-02, 4.1292932e-02, 3.3771273e-02],\n",
       "       [1.2428085e+00, 1.0435090e+00, 7.6342207e-01, 1.4271587e+00],\n",
       "       [6.4827787e-04, 1.6536245e-04, 1.4159907e-04, 1.4282916e-04],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = sparse @ dense\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dims = (M,K)\n",
    "\n",
    "out = np.empty((M,K), dtype=np.float32)\n",
    "out = np.zeros((M,K), dtype=np.float32)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this line would create a context\n",
    "cntxt = cl.create_some_context()\n",
    "#now create a command queue in the context\n",
    "queue = cl.CommandQueue(cntxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the buffers to hold the values of the input\n",
    "mf = cl.mem_flags\n",
    "sparse_buf = cl.Buffer(cntxt, mf.READ_ONLY | mf.COPY_HOST_PTR,hostbuf=sparse_to_dense)\n",
    "rowptr_buf = cl.Buffer(cntxt, mf.READ_ONLY | mf.COPY_HOST_PTR,hostbuf=rowptr)\n",
    "col_buf = cl.Buffer(cntxt, mf.READ_ONLY | mf.COPY_HOST_PTR,hostbuf=col)\n",
    "value_buf = cl.Buffer(cntxt, mf.READ_ONLY | mf.COPY_HOST_PTR,hostbuf=value)\n",
    "dense_buf = cl.Buffer(cntxt, mf.READ_ONLY | mf.COPY_HOST_PTR,hostbuf=dense)\n",
    "\n",
    "# create output buffer\n",
    "out_buf = cl.Buffer(cntxt, mf.WRITE_ONLY, out.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Program\n",
    "code = \"\"\"\n",
    "#define THREADS 256\n",
    "#define FULL_MASK 0xffffffff\n",
    "#define HAS_VALUE 1\n",
    "#define TS 32\n",
    "\n",
    "__kernel void spmm_kernel(const int B, const int M, const int N, const int K,\n",
    "                          const __global int* rowptr_data, const __global int* col_data,\n",
    "                          const __global float* value_data,\n",
    "                          const __global float* mat_data, __global float* out_data)\n",
    "{\n",
    "    // shared memory as shfl_sync replacement\n",
    "    __local int mat_rows[THREADS];\n",
    "    __local float vals[THREADS];\n",
    "    \n",
    "    // pretending to use 32 size warps by simulating 32 columns and 8 rows\n",
    "    int localrow = get_local_size(0) / 32;\n",
    "    int localcol = get_local_size(0) % 32;\n",
    "\n",
    "    // int thread_idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    // or \n",
    "    int thread_idx = get_global_id(0);\n",
    "    // int thread_idx = get_local_id(0) * get_group_id(0) + get_local_id(0);\n",
    "    int row = thread_idx >> 5;            // thread_idx / 32  \n",
    "    int lane_idx = thread_idx & (32 - 1); // thread_idx % 32  \n",
    "    int batch_idx = row / M;\n",
    "    \n",
    "    // Compute the column index of `mat` in which the thread is operating.\n",
    "    int mat_col_idx = lane_idx + (get_group_id(1) << 5);\n",
    "    \n",
    "    // Compute the output index (row-major order).\n",
    "    int out_idx = row * K + mat_col_idx;\n",
    "    \n",
    "    // Helper arrays for warp communication.\n",
    "    int mat_row; //, mat_rows[32];\n",
    "    int temp_mat_row;\n",
    "    float val; //, vals[HAS_VALUE ? 32 : 1];\n",
    "    \n",
    "    // Do not aggregate/write across the Y-axis (lane_idx < leftover).\n",
    "    int leftover = K - (get_group_id(1) << 5);\n",
    "    \n",
    "    if (batch_idx < B) {\n",
    "      // int row_start = __ldg(rowptr_data + (row % M));\n",
    "      // int row_end = __ldg(rowptr_data + (row % M) + 1);\n",
    "      int row_start = rowptr_data[(row % M)];\n",
    "      int row_end = rowptr_data[(row % M) + 1];\n",
    "      int col_idx = row_start + lane_idx;\n",
    "    \n",
    "      // scalar_t result = Reducer<scalar_t, REDUCE>::init();\n",
    "      // float result = 1;\n",
    "      float result = 0;\n",
    "      int arg;\n",
    "    \n",
    "      // Iterate over all `col` indices in parallel within a warp.\n",
    "      for (int c = row_start; c < row_end; c += 32) {\n",
    "\n",
    "        if (col_idx < row_end) {\n",
    "          // Coalesced memory access into `col` and `val`.\n",
    "          // mat_row = __ldg(col_data + col_idx) * K;\n",
    "          mat_row = col_data[col_idx] * K;\n",
    "          if (HAS_VALUE)\n",
    "            val = value_data[col_idx];\n",
    "        } else {\n",
    "          mat_row = -1;\n",
    "          if (HAS_VALUE)\n",
    "            val = (float)0;\n",
    "        }\n",
    "        col_idx += 32;\n",
    "        \n",
    "        \n",
    "  // #pragma unroll\n",
    "        // for (int i = 0; i < 32; i++) {\n",
    "          // Communication between all threads in a warp.\n",
    "          // https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html\n",
    "          // mat_rows[i] = __shfl_sync(FULL_MASK, mat_row, i);\n",
    "          // if (HAS_VALUE)\n",
    "            // vals[i] = __shfl_sync(FULL_MASK, val, i);\n",
    "      // }\n",
    "      \n",
    "    \n",
    "        mat_rows[get_local_id(0)] = mat_row;\n",
    "        vals[get_local_id(0)] = val;\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "        \n",
    "  #pragma unroll\n",
    "        for (int i = 0; i < 32; i++) {\n",
    "        // for (int i = 0; i < get_local_size(0); i++) {\n",
    "          // if (lane_idx < leftover && mat_rows[i] != -1) {\n",
    "          if (lane_idx < leftover && mat_rows[localrow*32 + i] != -1) {\n",
    "            // Coalesced memory access into `mat`.\n",
    "            // val = __ldg(mat_data + batch_idx * N * K + mat_rows[i] + mat_col_idx);\n",
    "            // val = mat_data[(batch_idx * N * K + mat_rows[localrow*32 + i] + mat_col_idx)];\n",
    "            temp_mat_row = mat_rows[localrow*32 + i];\n",
    "            val = mat_data[batch_idx*N*K + temp_mat_row + mat_col_idx];\n",
    "            if (HAS_VALUE)\n",
    "              val = vals[(localrow*32) + i] * val;\n",
    "            // Reducer<scalar_t, REDUCE>::update(&result, val, &arg, c + i);\n",
    "            // result *= val;\n",
    "            result += val;\n",
    "          }\n",
    "        }\n",
    "        \n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "      }\n",
    "      \n",
    "      if (lane_idx < leftover) {\n",
    "        // Coalesced write into `out`.\n",
    "        // Reducer<scalar_t, REDUCE>::write(out_data + out_idx, result,\n",
    "                                         // arg_out_data + out_idx, arg,\n",
    "                                         // row_end - row_start);\n",
    "        // *address = val;\n",
    "        out_data[out_idx] = result;\n",
    "      }\n",
    "    }  \n",
    "    \n",
    "    \n",
    "    // Just printing things into out to debug\n",
    "    /*int j = get_global_id(0) * get_global_id(1) * 256;\n",
    "    if (j == 254) {\n",
    "        out_data[0] = out_idx;\n",
    "        out_data[1] = mat_rows[localrow*32];\n",
    "        out_data[2] = batch_idx;\n",
    "    }*/\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Program\n",
    "code2 = \"\"\"\n",
    "__kernel void spmm_kernel(const int B, const int M, const int N, const int K,\n",
    "                          const __global int* rowptr_data, const __global int* col_data,\n",
    "                          const __global float* value_data,\n",
    "                          const __global float* mat_data, __global float* out_data)\n",
    "{\n",
    "    int i = get_global_id(0) * get_global_id(1) * 5;\n",
    "    if (i == 0) {\n",
    "        out_data[0] = B;\n",
    "        out_data[1] = M;\n",
    "        out_data[2] = N;\n",
    "        out_data[3] = K;\n",
    "        out_data[0] = get_local_size(0);\n",
    "        out_data[1] = get_local_size(1);\n",
    "        out_data[2] = get_global_size(0);\n",
    "        out_data[3] = get_global_size(1);\n",
    "        out_data[5] = get_local_size(0);\n",
    "        out_data[6] = get_local_size(1);\n",
    "        out_data[7] = get_global_size(0);\n",
    "        out_data[8] = get_global_size(1);\n",
    "        out_data[10] = value_data[0];\n",
    "        out_data[11] = col_data[1];\n",
    "        out_data[12] = mat_data[0];\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeX = \"\"\"\n",
    "#define TS   4\n",
    "#define WPT  1                         // The amount of work-per-thread, i.e. the thread-coarsening factor\n",
    "#define RTS  (TS/WPT)  \n",
    "\n",
    "// Increased the amount of work-per-thread by a factor WPT\n",
    "__kernel void spmm_kernel(const int M, const int N, const int K,\n",
    "                      const __global float* A,\n",
    "                      const __global float* B,\n",
    "                      __global float* C) {\n",
    "    int i = 1;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rowptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, (256, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(rowptr) - 1\n",
    "localrange = THREADS\n",
    "globalrange = (int((32 * B * m + THREADS - 1) / THREADS)*THREADS, int((K + 31) / 32))\n",
    "localrange, globalrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros((M,N), dtype=np.float32)\n",
    "\n",
    "# build the Kernel\n",
    "prg = cl.Program(cntxt, codeX).build()\n",
    "\n",
    "# to add scalar arguments\n",
    "# https://stackoverflow.com/questions/36725044/in-python-how-do-i-pass-a-scalar-argument-to-an-opencl-kernel \n",
    "# AND https://github.com/HandsOnOpenCL/Exercises-Solutions/blob/master/Solutions/Exercise04/Python/vadd_chain.py\n",
    "kernel = prg.spmm_kernel\n",
    "# kernel.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, None, None, None, None, None])\n",
    "kernel.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, None, None, None])\n",
    "\n",
    "# spmm_kernel<scalar_t, REDUCE, true><<<BLOCKS, THREADS, 0, stream>>>(...)\n",
    "localrange = None\n",
    "# auto BLOCKS = dim3((32 * B * M + THREADS - 1) / THREADS, (K + 31) / 32);\n",
    "globalrange = (int((32 * B * m + THREADS - 1) / THREADS)*THREADS, int((K + 31) / 32))\n",
    "\n",
    "# globalrange = out.shape\n",
    "# localrange = None\n",
    "\n",
    "# Kernel is now launched\n",
    "# launch = kernel(queue, globalrange, localrange, B, m, N, K, rowptr_buf, col_buf, value_buf, dense_buf, out_buf)\n",
    "launch = kernel(queue, globalrange, localrange, M, N, K, sparse_buf, dense_buf, out_buf)\n",
    "\n",
    "# wait till the process completes\n",
    "launch.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse:\n",
      "   (0, 0)\t0.05641158\n",
      "  (1, 0)\t0.72199875\n",
      "  (1, 1)\t0.93855274\n",
      "  (1, 3)\t0.9922116\n",
      "  (2, 3)\t0.0007787658\n",
      " [[5.6411579e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [7.2199875e-01 9.3855274e-01 0.0000000e+00 9.9221158e-01]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 7.7876583e-04]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "Dense:\n",
      " [[0.37454012 0.9507143  0.7319939  0.5986585 ]\n",
      " [0.15601864 0.15599452 0.05808361 0.8661761 ]\n",
      " [0.601115   0.7080726  0.02058449 0.96990985]\n",
      " [0.83244264 0.21233912 0.18182497 0.1834045 ]]\n",
      "Output:\n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#cl.enqueue_copy(queue, out, out_buf).wait()\n",
    "# print the output\n",
    "print (\"Sparse:\\n\", sparse)\n",
    "print (\"\", sparse.todense())\n",
    "print (\"Dense:\\n\", dense)\n",
    "print (\"Output:\\n\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right result:\n",
      " [[2.1128399e-02 5.3631295e-02 4.1292932e-02 3.3771273e-02]\n",
      " [1.2428085e+00 1.0435090e+00 7.6342207e-01 1.4271587e+00]\n",
      " [6.4827787e-04 1.6536245e-04 1.4159907e-04 1.4282916e-04]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "Output:\n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cl.enqueue_copy(queue, out, out_buf).wait()\n",
    "print (\"Right result:\\n\", result)\n",
    "print (\"Output:\\n\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/HandsOnOpenCL/Lecture-Slides/releases\n",
    "# Slide 191\n",
    "\n",
    "# CUDA\n",
    "#dim3 threads_per_block(30,20);\n",
    "\n",
    "#dim3 num_blocks(10,10);\n",
    "\n",
    "#kernel<<<num_blocks,\n",
    "#            threads_per_block>>>();\n",
    "    \n",
    "# OpenCL\n",
    "#const size_t global[2] =\n",
    "#                  {300, 200};\n",
    "\n",
    "#const size_t local[2] = \n",
    "#                  {30, 20};\n",
    "\n",
    "#clEnqueueNDRangeKernel(\n",
    "#       queue, &kernel,\n",
    "#       2, 0, &global, &local,\n",
    "#       0, NULL, NULL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cnugteren.github.io/tutorial/pages/page10.html\n",
    "# Replace __ldg with opencl syntax\n",
    "\n",
    "#    #ifdef USE_LDG\n",
    "#        floatX vecA = __ldg(&A[indexA]);\n",
    "#        floatX vecB = __ldg(&B[indexB]);\n",
    "#    #else\n",
    "#        floatX vecA = A[indexA];\n",
    "#        floatX vecB = B[indexB];\n",
    "#    #endif\n",
    "\n",
    "\n",
    "# Replace shuffle with opencl syntax\n",
    "\n",
    "#    // Cache the values of Bsub in registers\n",
    "#    #ifdef USE_SHUFFLE\n",
    "#        int col = tidn + (tidm % WPTN)*RTSN;\n",
    "#        float val = Bsub[k][col];\n",
    "#        for (int wn=0; wn<WPTN; wn++) {\n",
    "#            Breg[wn] = __shfl(val, wn, WPTN);\n",
    "#        }\n",
    "#    #else\n",
    "#        for (int wn=0; wn<WPTN; wn++) {\n",
    "#            int col = tidn + wn*RTSN;\n",
    "#            Breg[wn] = Bsub[k][col];\n",
    "#        }\n",
    "#    #endif\n",
    "\n",
    "# Shuffle vs shared memory\n",
    "# https://stackoverflow.com/questions/44278317/cuda-shuffle-instruction-reduction-slower-than-shared-memory-reduction\n",
    "\n",
    "# https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html\n",
    "# https://developer.nvidia.com/blog/register-cache-warp-cuda/\n",
    "\n",
    "# https://forums.developer.nvidia.com/t/difference-between-a-block-and-a-warp/7956\n",
    "# Blocks vs. warps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pragma once\n",
    "\n",
    "##include <limits>\n",
    "##include <map>\n",
    "\n",
    "#enum ReductionType { SUM, MEAN, MUL, DIV, MIN, MAX };\n",
    "\n",
    "#const std::map<std::string, ReductionType> reduce2REDUCE = {\n",
    "#    {\"sum\", SUM}, {\"mean\", MEAN}, {\"mul\", MUL},\n",
    "#    {\"div\", DIV}, {\"min\", MIN},   {\"max\", MAX},\n",
    "#};\n",
    "\n",
    "##define AT_DISPATCH_REDUCTION_TYPES(reduce, ...)                               \\\n",
    "#  [&] {                                                                        \\\n",
    "#    switch (reduce2REDUCE.at(reduce)) {                                        \\\n",
    "#    case SUM: {                                                                \\\n",
    "#      const ReductionType REDUCE = SUM;                                        \\\n",
    "#      return __VA_ARGS__();                                                    \\\n",
    "#    }                                                                          \\\n",
    "#    case MEAN: {                                                               \\\n",
    "#      const ReductionType REDUCE = MEAN;                                       \\\n",
    "#      return __VA_ARGS__();                                                    \\\n",
    "#    }                                                                          \\\n",
    "#    case MUL: {                                                                \\\n",
    "#      const ReductionType REDUCE = MUL;                                        \\\n",
    "#      return __VA_ARGS__();                                                    \\\n",
    "#    }                                                                          \\\n",
    "#    case DIV: {                                                                \\\n",
    "#      const ReductionType REDUCE = DIV;                                        \\\n",
    "#      return __VA_ARGS__();                                                    \\\n",
    "#    }                                                                          \\\n",
    "#    case MIN: {                                                                \\\n",
    "#      const ReductionType REDUCE = MIN;                                        \\\n",
    "#      return __VA_ARGS__();                                                    \\\n",
    "#    }                                                                          \\\n",
    "#    case MAX: {                                                                \\\n",
    "#      const ReductionType REDUCE = MAX;                                        \\\n",
    "#      return __VA_ARGS__();                                                    \\\n",
    "#    }                                                                          \\\n",
    "#    }                                                                          \\\n",
    "#  }()\n",
    "\n",
    "#template <typename scalar_t, ReductionType REDUCE> struct Reducer {\n",
    "#  static inline __host__ __device__ scalar_t init() {\n",
    "#    if (REDUCE == MUL || REDUCE == DIV)\n",
    "#      return (scalar_t)1;\n",
    "#    else if (REDUCE == MIN)\n",
    "#      return std::numeric_limits<scalar_t>::max();\n",
    "#    else if (REDUCE == MAX)\n",
    "#      return std::numeric_limits<scalar_t>::lowest();\n",
    "#    else\n",
    "#      return (scalar_t)0;\n",
    "#  }\n",
    "\n",
    "#  static inline __host__ __device__ void update(scalar_t *val, scalar_t new_val,\n",
    "#                                                int64_t *arg, int64_t new_arg) {\n",
    "#    if (REDUCE == SUM || REDUCE == MEAN)\n",
    "#      *val = *val + new_val;\n",
    "#    else if (REDUCE == MUL)\n",
    "#      *val = *val * new_val;\n",
    "#    else if (REDUCE == DIV)\n",
    "#      *val = *val / new_val;\n",
    "#    else if ((REDUCE == MIN && new_val < *val) ||\n",
    "#             (REDUCE == MAX && new_val > *val)) {\n",
    "#      *val = new_val;\n",
    "#      *arg = new_arg;\n",
    "#    }\n",
    "#  }\n",
    "\n",
    "#  static inline __host__ __device__ void write(scalar_t *address, scalar_t val,\n",
    "#                                               int64_t *arg_address,\n",
    "#                                               int64_t arg, int count) {\n",
    "#    if (REDUCE == SUM || REDUCE == MUL || REDUCE == DIV)\n",
    "#      *address = val;\n",
    "#    else if (REDUCE == MEAN)\n",
    "#      *address = val / (count > 0 ? count : (scalar_t)1);\n",
    "#    else if (REDUCE == MIN || REDUCE == MAX) {\n",
    "#      if (count > 0) {\n",
    "#        *address = val;\n",
    "#        *arg_address = arg;\n",
    "#      } else\n",
    "#        *address = (scalar_t)0;\n",
    "#    }\n",
    "#  }\n",
    "#};"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
